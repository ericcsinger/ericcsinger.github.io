<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Storage on Eric&#39;s Blog</title>
    <link>https://ericcsinger.com/categories/storage/</link>
    <description>Recent content in Storage on Eric&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>©2025, Eric C. Singer
</copyright>
    <lastBuildDate>Fri, 19 Aug 2016 23:45:00 +0000</lastBuildDate><atom:link href="https://ericcsinger.com/categories/storage/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Wish list: Nimble Storage (2016)</title>
      <link>https://ericcsinger.com/wish-list-nimble-storage-2016/</link>
      <pubDate>Fri, 19 Aug 2016 23:45:00 +0000</pubDate>
      <guid>https://ericcsinger.com/wish-list-nimble-storage-2016/</guid>
      <description><![CDATA[<h1 id="introduction" data-numberify>Introduction:<a class="anchor ms-1" href="#introduction"></a></h1>
<p>These are just some random things that I would love to see implemented by Nimble Storage in their solution. I don’t actually expect most of this stuff to happen in a year, but it would be interesting to see how many do. Some are more realistic than others of course, but part of the fun in this is asking for some stuff that perhaps is a bit of a stretch.</p>]]></description>
    </item>
    
    <item>
      <title>Backup Storage Part 3a: Deduplication Targets</title>
      <link>https://ericcsinger.com/backup-storage-part-3a-deduplication-targets/</link>
      <pubDate>Tue, 02 Jun 2015 21:08:31 +0000</pubDate>
      <guid>https://ericcsinger.com/backup-storage-part-3a-deduplication-targets/</guid>
      <description><![CDATA[<p>Deduplication and backup kind of go hand in hand, so we couldn’t evaluate backup storage and not check out this segment. We had two primary goals for a deduplication appliance.</p>
<ol>
<li>Reduce racks space while enabling us to store more data. As you know in part 1, we had a lot of rack space being consumed. While we weren’t hurting for rack space in our primary DC, we were in our DR DC.</li>
<li>We were hoping that something like a deduplication target would finally enable us to get rid of tape and replicate our data to our DR site (instead of sneakernet).</li>
</ol>
<p>For those of you not particularly versed in deduplicated storage, there are a few things to keep in mind.</p>]]></description>
    </item>
    
    <item>
      <title>Backup Storage Part 2: What we wanted</title>
      <link>https://ericcsinger.com/backup-storage-part-2-what-we-wanted/</link>
      <pubDate>Fri, 01 May 2015 20:59:30 +0000</pubDate>
      <guid>https://ericcsinger.com/backup-storage-part-2-what-we-wanted/</guid>
      <description><![CDATA[<p>In part 1, I went over our legacy backup storage solution, and why it needed to change. This section, I’m going to outline what we were looking for in our next storage refresh.</p>
<p>Also, just to give you a little more context, while evaluating storage, were also looking at new backup solutions. CommVault, Veeam, EMC (Avamar and Networker), NetVault, Microsoft DPM, and a handful of cloud solutions. Point being, there were a lot of moving parts and a lot of things to consider. I’ll dive more into this in the coming sections, but wanted to let you know it was more than just a simple storage refresh.</p>]]></description>
    </item>
    
    <item>
      <title>Backup Storage Part 1: Why it needed to change</title>
      <link>https://ericcsinger.com/backup-storage-part-1-why-it-needed-to-change/</link>
      <pubDate>Tue, 21 Apr 2015 16:46:46 +0000</pubDate>
      <guid>https://ericcsinger.com/backup-storage-part-1-why-it-needed-to-change/</guid>
      <description><![CDATA[<h1 id="introduction" data-numberify>Introduction:<a class="anchor ms-1" href="#introduction"></a></h1>
<p>This is going to be a multi-part series where I walk you through the whole process we took in evaluating, implementing and living with a new backup storage solution. While its not a perfect solution, given the parameters we had to work within, I think we ended up with some very decent storage.</p>

<h1 id="backup-storage-part-1-the-why-it-needed-to-change" data-numberify>Backup Storage Part 1: The “Why” it needed to change<a class="anchor ms-1" href="#backup-storage-part-1-the-why-it-needed-to-change"></a></h1>
<p>Last year my team and I began a project to overhaul our backup solution and part of that solution involved researching some new storage options. At the time, we ran what most folks would on a budget, which is simply a server, with some local DAS. It was a Dell 2900 (IIRC) with 6 MD1000’s and 1 MD1200. The solution was originally designed to manage about 10TB of data, and really was never expected to handle what ultimately ended up being much greater than that. The solution was less than ideal for a lot of reasons that I’m sharing below.</p>]]></description>
    </item>
    
  </channel>
</rss>

